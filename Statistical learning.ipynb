{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statstical Learning\n",
    "\n",
    "We will be applying the statistical learning concepts and tools that we have learned. In particular, we will go back to the dataset that we used in the first notebook (which contains data about breast cancer) and design algorithms to diagnose whether a given tumor is benign or malignant.\n",
    "\n",
    "\n",
    "# Statistical learning using scikit-learn\n",
    "\n",
    "In this session we will be using [scikit-learn](https://scikit-learn.org/stable/index.html), the major machine learning module for Python.\n",
    "\n",
    "![Scikit Learn](Media/sklearn.png)\n",
    "\n",
    "This module is installed by default in Anaconda, so this time you would not really need to worry about `pip install`, installation errors or any of that. But let's do it anyway, just to make sure that everyone is running the latest version :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user --upgrade scikit-learn xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final exercise you will be needing tools for: logistic regression, random forests, support vector machines, and cross-validation. Here are a few pointers.\n",
    "\n",
    "\n",
    "## Logistic regression\n",
    "\n",
    "As discussed in the theoretical lectures, logistic regression can be considered the simplest approach for classification. In `scikit-learn`, all classification approaches have a similar interface, so that using logistic regression is not very different from using a neural network. \n",
    "\n",
    "Let's quickly see this. First, we load some predefined data: the iris dataset. This is perhaps the best known database to be found in the classification literature. The data set contains 150 points corresponding to 3 classes, where each class refers to a type of iris plant. Each point is characterized by 4 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) for sample number 60: [5.  2.  3.5 1. ]\n",
      "Response (y) for sample number 60:   1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "print('Features (X) for sample number 60:', X[60])\n",
    "print('Response (y) for sample number 60:  ', y[60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that sample 60 in the data set corresponds to an iris plant of type $y=1$, and that the four features characterizing this sample take values $x_1=5$, $x_2=2$, $x_3=3.5$ and $x_4=1$. Now let's build and fit a logistic regression classifier for the dataset. This logistic regression will try to predict the type of iris $y$ from the features $(x_1, x_2, x_3, x_4)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now we can predict the class of a new, imaginary instance with features [6.2, 3.1, 5.8, 2.4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = [[6.2, 3.1, 5.8, 2.4]]\n",
    "clf.predict(X_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Logistic regression is described in all detail [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "## Random forests\n",
    "\n",
    "As discussed in the theoretical lectures, random forests (RFs) are powerful and flexible statistical learning methods. Training a RF and making predictions with it is analogous to logistic regression. The scikit-learn implementation of RFs and their use are described [here](https://scikit-learn.org/stable/modules/ensemble.html#forest).\n",
    "\n",
    "## Support vector machines\n",
    "\n",
    "Support vector machines (SVMs) are also powerful models. The training of SVMs and making predictions with them is analogous to logistic regression, and is described in detail [here](https://scikit-learn.org/stable/modules/svm.html#svm-classification).\n",
    "\n",
    "## Neural networks\n",
    "\n",
    "Finally, simple neural networks (multilayer perceptrons), which can be used pretty much like all previous approaches, are described [here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html).\n",
    "\n",
    "## Cross validation\n",
    "\n",
    "As we have seen in the lectures, if we evaluate the prediction error of a model on the same data that we use to train it, we are likely to overfit and to underestimate the test error. Cross-validation is a technique for evaluating the prediction error of our models robustly. As we have also seen, there are several approaches to cross-validation, notably k-fold cross-validation and leave-one-out cross-validation.\n",
    "\n",
    "Cross-validation in scikit-learn is discussed in detail [here](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation). For the final exercise, we will be using k-fold cross-validation to select the best parameters for our SVM models. There are basically three ways of doing this: using KFold iterators as discussed [here](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators) and, more specifically, [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold); using cross-validated metrics as described [here](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics); or using parameter tuning as discussed [here](https://scikit-learn.org/stable/modules/grid_search.html). These methods are increasingly sophisticated, increasingly difficut to understand, and increasingly easy to use. You will have to choose!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exercise - Diagnosing malignant breast cancer\n",
    "\n",
    "Here you will consider, again, the [Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data#data.csv). The features in this data set are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. Each row in the dataset corresponds to a given patient; each column describes a characteristic of the cell nuclei present in the image. Additionally, the *malignant* column specifies whether the tumor is benign (value 0 or `False`) or malignant (value 1 or `True`).  The training and test data for this exercise are available from the files `Files/TRAIN_breast_cancer_kaggle.xls` and `Files/TEST_breast_cancer_kaggle.xls`, respectively. You will be using statistical learning to predict if a given tumor is benign or malignant.\n",
    "\n",
    "1. Load the training breast cancer data into a Pandas data frame (if you do not remember how to do this, check the notebook of Session 1 or read the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) for the `read_excel()` method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.10</td>\n",
       "      <td>17.72</td>\n",
       "      <td>78.07</td>\n",
       "      <td>446.2</td>\n",
       "      <td>0.10290</td>\n",
       "      <td>0.09758</td>\n",
       "      <td>0.04783</td>\n",
       "      <td>0.03326</td>\n",
       "      <td>0.1937</td>\n",
       "      <td>0.06161</td>\n",
       "      <td>...</td>\n",
       "      <td>25.80</td>\n",
       "      <td>88.33</td>\n",
       "      <td>559.5</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.06266</td>\n",
       "      <td>0.3049</td>\n",
       "      <td>0.07081</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.71</td>\n",
       "      <td>20.39</td>\n",
       "      <td>69.50</td>\n",
       "      <td>344.9</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.08448</td>\n",
       "      <td>0.02867</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.06862</td>\n",
       "      <td>...</td>\n",
       "      <td>25.21</td>\n",
       "      <td>76.51</td>\n",
       "      <td>410.4</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.08701</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>19.32</td>\n",
       "      <td>115.10</td>\n",
       "      <td>951.6</td>\n",
       "      <td>0.08968</td>\n",
       "      <td>0.11980</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.07488</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.05491</td>\n",
       "      <td>...</td>\n",
       "      <td>25.84</td>\n",
       "      <td>139.50</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>0.19390</td>\n",
       "      <td>0.2928</td>\n",
       "      <td>0.07867</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.95</td>\n",
       "      <td>17.57</td>\n",
       "      <td>96.85</td>\n",
       "      <td>678.1</td>\n",
       "      <td>0.11670</td>\n",
       "      <td>0.13050</td>\n",
       "      <td>0.15390</td>\n",
       "      <td>0.08624</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.06216</td>\n",
       "      <td>...</td>\n",
       "      <td>21.43</td>\n",
       "      <td>121.40</td>\n",
       "      <td>971.4</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.16670</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.07147</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.91</td>\n",
       "      <td>16.33</td>\n",
       "      <td>82.53</td>\n",
       "      <td>516.4</td>\n",
       "      <td>0.07941</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.03873</td>\n",
       "      <td>0.02377</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>22.00</td>\n",
       "      <td>90.81</td>\n",
       "      <td>600.6</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.08235</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.06949</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        12.10         17.72           78.07      446.2          0.10290   \n",
       "1        10.71         20.39           69.50      344.9          0.10820   \n",
       "2        17.54         19.32          115.10      951.6          0.08968   \n",
       "3        14.95         17.57           96.85      678.1          0.11670   \n",
       "4        12.91         16.33           82.53      516.4          0.07941   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.09758         0.04783              0.03326         0.1937   \n",
       "1           0.12890         0.08448              0.02867         0.1668   \n",
       "2           0.11980         0.10360              0.07488         0.1506   \n",
       "3           0.13050         0.15390              0.08624         0.1957   \n",
       "4           0.05366         0.03873              0.02377         0.1829   \n",
       "\n",
       "   fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                 0.06161  ...          25.80            88.33       559.5   \n",
       "1                 0.06862  ...          25.21            76.51       410.4   \n",
       "2                 0.05491  ...          25.84           139.50      1239.0   \n",
       "3                 0.06216  ...          21.43           121.40       971.4   \n",
       "4                 0.05667  ...          22.00            90.81       600.6   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1432             0.1773           0.1603               0.06266   \n",
       "1            0.1335             0.2550           0.2534               0.08600   \n",
       "2            0.1381             0.3420           0.3508               0.19390   \n",
       "3            0.1411             0.2164           0.3355               0.16670   \n",
       "4            0.1097             0.1506           0.1764               0.08235   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  malignant  \n",
       "0          0.3049                  0.07081      False  \n",
       "1          0.2605                  0.08701      False  \n",
       "2          0.2928                  0.07867       True  \n",
       "3          0.3414                  0.07147       True  \n",
       "4          0.3024                  0.06949      False  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Files/TRAIN_breast_cancer_kaggle.xls')\n",
    "display(df.head()) #per comprovar si ho he obert bé i veure el tipus de dades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Store the column corresponding to the response variable *malignant* into a variable named `y`. Store all other columns (corresponding to the features) into a Pandas `DataFrame` variable named `X`, whose columns correspond to features and whose rows correspond to patients, just as in the original Excel file (but without the *malignant* column). Display `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.10</td>\n",
       "      <td>17.72</td>\n",
       "      <td>78.07</td>\n",
       "      <td>446.2</td>\n",
       "      <td>0.10290</td>\n",
       "      <td>0.09758</td>\n",
       "      <td>0.04783</td>\n",
       "      <td>0.03326</td>\n",
       "      <td>0.1937</td>\n",
       "      <td>0.06161</td>\n",
       "      <td>...</td>\n",
       "      <td>13.56</td>\n",
       "      <td>25.80</td>\n",
       "      <td>88.33</td>\n",
       "      <td>559.5</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.06266</td>\n",
       "      <td>0.3049</td>\n",
       "      <td>0.07081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.71</td>\n",
       "      <td>20.39</td>\n",
       "      <td>69.50</td>\n",
       "      <td>344.9</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.08448</td>\n",
       "      <td>0.02867</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.06862</td>\n",
       "      <td>...</td>\n",
       "      <td>11.69</td>\n",
       "      <td>25.21</td>\n",
       "      <td>76.51</td>\n",
       "      <td>410.4</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.08701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.54</td>\n",
       "      <td>19.32</td>\n",
       "      <td>115.10</td>\n",
       "      <td>951.6</td>\n",
       "      <td>0.08968</td>\n",
       "      <td>0.11980</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.07488</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.05491</td>\n",
       "      <td>...</td>\n",
       "      <td>20.42</td>\n",
       "      <td>25.84</td>\n",
       "      <td>139.50</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>0.19390</td>\n",
       "      <td>0.2928</td>\n",
       "      <td>0.07867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.95</td>\n",
       "      <td>17.57</td>\n",
       "      <td>96.85</td>\n",
       "      <td>678.1</td>\n",
       "      <td>0.11670</td>\n",
       "      <td>0.13050</td>\n",
       "      <td>0.15390</td>\n",
       "      <td>0.08624</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.06216</td>\n",
       "      <td>...</td>\n",
       "      <td>18.55</td>\n",
       "      <td>21.43</td>\n",
       "      <td>121.40</td>\n",
       "      <td>971.4</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.16670</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.07147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.91</td>\n",
       "      <td>16.33</td>\n",
       "      <td>82.53</td>\n",
       "      <td>516.4</td>\n",
       "      <td>0.07941</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.03873</td>\n",
       "      <td>0.02377</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>13.88</td>\n",
       "      <td>22.00</td>\n",
       "      <td>90.81</td>\n",
       "      <td>600.6</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.08235</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.06949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>13.11</td>\n",
       "      <td>22.54</td>\n",
       "      <td>87.02</td>\n",
       "      <td>529.4</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.14830</td>\n",
       "      <td>0.08705</td>\n",
       "      <td>0.05102</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.07310</td>\n",
       "      <td>...</td>\n",
       "      <td>14.55</td>\n",
       "      <td>29.16</td>\n",
       "      <td>99.48</td>\n",
       "      <td>639.3</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.4402</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.4128</td>\n",
       "      <td>0.10760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>11.89</td>\n",
       "      <td>18.35</td>\n",
       "      <td>77.32</td>\n",
       "      <td>432.2</td>\n",
       "      <td>0.09363</td>\n",
       "      <td>0.11540</td>\n",
       "      <td>0.06636</td>\n",
       "      <td>0.03142</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06314</td>\n",
       "      <td>...</td>\n",
       "      <td>13.25</td>\n",
       "      <td>27.10</td>\n",
       "      <td>86.20</td>\n",
       "      <td>531.2</td>\n",
       "      <td>0.1405</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.11380</td>\n",
       "      <td>0.3397</td>\n",
       "      <td>0.08365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>13.08</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>14.47</td>\n",
       "      <td>24.99</td>\n",
       "      <td>95.81</td>\n",
       "      <td>656.4</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.10090</td>\n",
       "      <td>0.03890</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.06341</td>\n",
       "      <td>...</td>\n",
       "      <td>16.22</td>\n",
       "      <td>31.73</td>\n",
       "      <td>113.50</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.4202</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>13.66</td>\n",
       "      <td>15.15</td>\n",
       "      <td>88.27</td>\n",
       "      <td>580.6</td>\n",
       "      <td>0.08268</td>\n",
       "      <td>0.07548</td>\n",
       "      <td>0.04249</td>\n",
       "      <td>0.02471</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.05897</td>\n",
       "      <td>...</td>\n",
       "      <td>14.54</td>\n",
       "      <td>19.64</td>\n",
       "      <td>97.96</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.3104</td>\n",
       "      <td>0.2569</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.3387</td>\n",
       "      <td>0.09638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          12.10         17.72           78.07      446.2          0.10290   \n",
       "1          10.71         20.39           69.50      344.9          0.10820   \n",
       "2          17.54         19.32          115.10      951.6          0.08968   \n",
       "3          14.95         17.57           96.85      678.1          0.11670   \n",
       "4          12.91         16.33           82.53      516.4          0.07941   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "395        13.11         22.54           87.02      529.4          0.10020   \n",
       "396        11.89         18.35           77.32      432.2          0.09363   \n",
       "397        13.08         15.71           85.63      520.0          0.10750   \n",
       "398        14.47         24.99           95.81      656.4          0.08837   \n",
       "399        13.66         15.15           88.27      580.6          0.08268   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.09758         0.04783              0.03326         0.1937   \n",
       "1             0.12890         0.08448              0.02867         0.1668   \n",
       "2             0.11980         0.10360              0.07488         0.1506   \n",
       "3             0.13050         0.15390              0.08624         0.1957   \n",
       "4             0.05366         0.03873              0.02377         0.1829   \n",
       "..                ...             ...                  ...            ...   \n",
       "395           0.14830         0.08705              0.05102         0.1850   \n",
       "396           0.11540         0.06636              0.03142         0.1967   \n",
       "397           0.12700         0.04568              0.03110         0.1967   \n",
       "398           0.12300         0.10090              0.03890         0.1872   \n",
       "399           0.07548         0.04249              0.02471         0.1792   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.06161  ...         13.56          25.80   \n",
       "1                   0.06862  ...         11.69          25.21   \n",
       "2                   0.05491  ...         20.42          25.84   \n",
       "3                   0.06216  ...         18.55          21.43   \n",
       "4                   0.05667  ...         13.88          22.00   \n",
       "..                      ...  ...           ...            ...   \n",
       "395                 0.07310  ...         14.55          29.16   \n",
       "396                 0.06314  ...         13.25          27.10   \n",
       "397                 0.06811  ...         14.50          20.49   \n",
       "398                 0.06341  ...         16.22          31.73   \n",
       "399                 0.05897  ...         14.54          19.64   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0              88.33       559.5            0.1432             0.1773   \n",
       "1              76.51       410.4            0.1335             0.2550   \n",
       "2             139.50      1239.0            0.1381             0.3420   \n",
       "3             121.40       971.4            0.1411             0.2164   \n",
       "4              90.81       600.6            0.1097             0.1506   \n",
       "..               ...         ...               ...                ...   \n",
       "395            99.48       639.3            0.1349             0.4402   \n",
       "396            86.20       531.2            0.1405             0.3046   \n",
       "397            96.09       630.5            0.1312             0.2776   \n",
       "398           113.50       808.9            0.1340             0.4202   \n",
       "399            97.96       657.0            0.1275             0.3104   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.1603               0.06266          0.3049   \n",
       "1             0.2534               0.08600          0.2605   \n",
       "2             0.3508               0.19390          0.2928   \n",
       "3             0.3355               0.16670          0.3414   \n",
       "4             0.1764               0.08235          0.3024   \n",
       "..               ...                   ...             ...   \n",
       "395           0.3162               0.11260          0.4128   \n",
       "396           0.2806               0.11380          0.3397   \n",
       "397           0.1890               0.07283          0.3184   \n",
       "398           0.4040               0.12050          0.3187   \n",
       "399           0.2569               0.10540          0.3387   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.07081  \n",
       "1                    0.08701  \n",
       "2                    0.07867  \n",
       "3                    0.07147  \n",
       "4                    0.06949  \n",
       "..                       ...  \n",
       "395                  0.10760  \n",
       "396                  0.08365  \n",
       "397                  0.08183  \n",
       "398                  0.10230  \n",
       "399                  0.09638  \n",
       "\n",
       "[400 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2       True\n",
       "3       True\n",
       "4      False\n",
       "       ...  \n",
       "395    False\n",
       "396    False\n",
       "397    False\n",
       "398    False\n",
       "399    False\n",
       "Name: malignant, Length: 400, dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df.iloc[:, 0:30] #aprofitant que a la descripció anterior hi ha 31 columnes i volem excloure l'última\n",
    "y = df['malignant']\n",
    "\n",
    "display(x)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Do the same for the test data, building the corresponding `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.981</td>\n",
       "      <td>13.43</td>\n",
       "      <td>43.79</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.07568</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>...</td>\n",
       "      <td>19.54</td>\n",
       "      <td>50.41</td>\n",
       "      <td>185.2</td>\n",
       "      <td>0.15840</td>\n",
       "      <td>0.12020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.09382</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.290</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.30</td>\n",
       "      <td>632.6</td>\n",
       "      <td>0.06429</td>\n",
       "      <td>0.02675</td>\n",
       "      <td>0.00725</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.05376</td>\n",
       "      <td>...</td>\n",
       "      <td>20.65</td>\n",
       "      <td>94.44</td>\n",
       "      <td>684.6</td>\n",
       "      <td>0.08567</td>\n",
       "      <td>0.05036</td>\n",
       "      <td>0.03866</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06120</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.550</td>\n",
       "      <td>28.77</td>\n",
       "      <td>133.60</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>0.09260</td>\n",
       "      <td>0.20630</td>\n",
       "      <td>0.17840</td>\n",
       "      <td>0.11440</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>0.06232</td>\n",
       "      <td>...</td>\n",
       "      <td>36.27</td>\n",
       "      <td>178.60</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>0.12810</td>\n",
       "      <td>0.53290</td>\n",
       "      <td>0.42510</td>\n",
       "      <td>0.19410</td>\n",
       "      <td>0.2818</td>\n",
       "      <td>0.10050</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.530</td>\n",
       "      <td>10.94</td>\n",
       "      <td>87.91</td>\n",
       "      <td>559.2</td>\n",
       "      <td>0.12910</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.06556</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.06641</td>\n",
       "      <td>...</td>\n",
       "      <td>12.49</td>\n",
       "      <td>91.36</td>\n",
       "      <td>605.5</td>\n",
       "      <td>0.14510</td>\n",
       "      <td>0.13790</td>\n",
       "      <td>0.08539</td>\n",
       "      <td>0.07407</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.07191</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        6.981         13.43           43.79      143.5          0.11700   \n",
       "1       14.290         16.82           90.30      632.6          0.06429   \n",
       "2       20.130         28.25          131.20     1261.0          0.09780   \n",
       "3       19.550         28.77          133.60     1207.0          0.09260   \n",
       "4       13.530         10.94           87.91      559.2          0.12910   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.07568         0.00000              0.00000         0.1930   \n",
       "1           0.02675         0.00725              0.00625         0.1508   \n",
       "2           0.10340         0.14400              0.09791         0.1752   \n",
       "3           0.20630         0.17840              0.11440         0.1893   \n",
       "4           0.10470         0.06877              0.06556         0.2403   \n",
       "\n",
       "   fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                 0.07818  ...          19.54            50.41       185.2   \n",
       "1                 0.05376  ...          20.65            94.44       684.6   \n",
       "2                 0.05533  ...          38.25           155.00      1731.0   \n",
       "3                 0.06232  ...          36.27           178.60      1926.0   \n",
       "4                 0.06641  ...          12.49            91.36       605.5   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0           0.15840            0.12020          0.00000               0.00000   \n",
       "1           0.08567            0.05036          0.03866               0.03333   \n",
       "2           0.11660            0.19220          0.32150               0.16280   \n",
       "3           0.12810            0.53290          0.42510               0.19410   \n",
       "4           0.14510            0.13790          0.08539               0.07407   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  malignant  \n",
       "0          0.2932                  0.09382      False  \n",
       "1          0.2458                  0.06120      False  \n",
       "2          0.2572                  0.06637       True  \n",
       "3          0.2818                  0.10050       True  \n",
       "4          0.2710                  0.07191      False  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.981</td>\n",
       "      <td>13.43</td>\n",
       "      <td>43.79</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.07568</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>...</td>\n",
       "      <td>7.93</td>\n",
       "      <td>19.54</td>\n",
       "      <td>50.41</td>\n",
       "      <td>185.2</td>\n",
       "      <td>0.15840</td>\n",
       "      <td>0.12020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.09382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.290</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.30</td>\n",
       "      <td>632.6</td>\n",
       "      <td>0.06429</td>\n",
       "      <td>0.02675</td>\n",
       "      <td>0.00725</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.05376</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>20.65</td>\n",
       "      <td>94.44</td>\n",
       "      <td>684.6</td>\n",
       "      <td>0.08567</td>\n",
       "      <td>0.05036</td>\n",
       "      <td>0.03866</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.550</td>\n",
       "      <td>28.77</td>\n",
       "      <td>133.60</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>0.09260</td>\n",
       "      <td>0.20630</td>\n",
       "      <td>0.17840</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>0.06232</td>\n",
       "      <td>...</td>\n",
       "      <td>25.05</td>\n",
       "      <td>36.27</td>\n",
       "      <td>178.60</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>0.12810</td>\n",
       "      <td>0.53290</td>\n",
       "      <td>0.42510</td>\n",
       "      <td>0.19410</td>\n",
       "      <td>0.2818</td>\n",
       "      <td>0.10050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.530</td>\n",
       "      <td>10.94</td>\n",
       "      <td>87.91</td>\n",
       "      <td>559.2</td>\n",
       "      <td>0.12910</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.065560</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.06641</td>\n",
       "      <td>...</td>\n",
       "      <td>14.08</td>\n",
       "      <td>12.49</td>\n",
       "      <td>91.36</td>\n",
       "      <td>605.5</td>\n",
       "      <td>0.14510</td>\n",
       "      <td>0.13790</td>\n",
       "      <td>0.08539</td>\n",
       "      <td>0.07407</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.07191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>12.060</td>\n",
       "      <td>18.90</td>\n",
       "      <td>76.66</td>\n",
       "      <td>445.3</td>\n",
       "      <td>0.08386</td>\n",
       "      <td>0.05794</td>\n",
       "      <td>0.00751</td>\n",
       "      <td>0.008488</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>0.06048</td>\n",
       "      <td>...</td>\n",
       "      <td>13.64</td>\n",
       "      <td>27.06</td>\n",
       "      <td>86.54</td>\n",
       "      <td>562.6</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.13520</td>\n",
       "      <td>0.04506</td>\n",
       "      <td>0.05093</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.08083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>15.460</td>\n",
       "      <td>11.89</td>\n",
       "      <td>102.50</td>\n",
       "      <td>736.9</td>\n",
       "      <td>0.12570</td>\n",
       "      <td>0.15550</td>\n",
       "      <td>0.20320</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>0.07069</td>\n",
       "      <td>...</td>\n",
       "      <td>18.79</td>\n",
       "      <td>17.04</td>\n",
       "      <td>125.00</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>0.15310</td>\n",
       "      <td>0.35830</td>\n",
       "      <td>0.58300</td>\n",
       "      <td>0.18270</td>\n",
       "      <td>0.3216</td>\n",
       "      <td>0.10100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>11.040</td>\n",
       "      <td>14.93</td>\n",
       "      <td>70.67</td>\n",
       "      <td>372.7</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>0.07079</td>\n",
       "      <td>0.03546</td>\n",
       "      <td>0.020740</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.06246</td>\n",
       "      <td>...</td>\n",
       "      <td>12.09</td>\n",
       "      <td>20.83</td>\n",
       "      <td>79.73</td>\n",
       "      <td>447.1</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>0.19820</td>\n",
       "      <td>0.15530</td>\n",
       "      <td>0.06754</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.07287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>21.710</td>\n",
       "      <td>17.25</td>\n",
       "      <td>140.90</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>0.09384</td>\n",
       "      <td>0.08562</td>\n",
       "      <td>0.11680</td>\n",
       "      <td>0.084650</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.05054</td>\n",
       "      <td>...</td>\n",
       "      <td>30.75</td>\n",
       "      <td>26.44</td>\n",
       "      <td>199.50</td>\n",
       "      <td>3143.0</td>\n",
       "      <td>0.13630</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.28610</td>\n",
       "      <td>0.18200</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.06494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.06924</td>\n",
       "      <td>...</td>\n",
       "      <td>17.62</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.66430</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          6.981         13.43           43.79      143.5          0.11700   \n",
       "1         14.290         16.82           90.30      632.6          0.06429   \n",
       "2         20.130         28.25          131.20     1261.0          0.09780   \n",
       "3         19.550         28.77          133.60     1207.0          0.09260   \n",
       "4         13.530         10.94           87.91      559.2          0.12910   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "164       12.060         18.90           76.66      445.3          0.08386   \n",
       "165       15.460         11.89          102.50      736.9          0.12570   \n",
       "166       11.040         14.93           70.67      372.7          0.07987   \n",
       "167       21.710         17.25          140.90     1546.0          0.09384   \n",
       "168       14.580         21.53           97.41      644.8          0.10540   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.07568         0.00000             0.000000         0.1930   \n",
       "1             0.02675         0.00725             0.006250         0.1508   \n",
       "2             0.10340         0.14400             0.097910         0.1752   \n",
       "3             0.20630         0.17840             0.114400         0.1893   \n",
       "4             0.10470         0.06877             0.065560         0.2403   \n",
       "..                ...             ...                  ...            ...   \n",
       "164           0.05794         0.00751             0.008488         0.1555   \n",
       "165           0.15550         0.20320             0.109700         0.1966   \n",
       "166           0.07079         0.03546             0.020740         0.2003   \n",
       "167           0.08562         0.11680             0.084650         0.1717   \n",
       "168           0.18680         0.14250             0.087830         0.2252   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.07818  ...          7.93          19.54   \n",
       "1                   0.05376  ...         14.91          20.65   \n",
       "2                   0.05533  ...         23.69          38.25   \n",
       "3                   0.06232  ...         25.05          36.27   \n",
       "4                   0.06641  ...         14.08          12.49   \n",
       "..                      ...  ...           ...            ...   \n",
       "164                 0.06048  ...         13.64          27.06   \n",
       "165                 0.07069  ...         18.79          17.04   \n",
       "166                 0.06246  ...         12.09          20.83   \n",
       "167                 0.05054  ...         30.75          26.44   \n",
       "168                 0.06924  ...         17.62          33.21   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0              50.41       185.2           0.15840            0.12020   \n",
       "1              94.44       684.6           0.08567            0.05036   \n",
       "2             155.00      1731.0           0.11660            0.19220   \n",
       "3             178.60      1926.0           0.12810            0.53290   \n",
       "4              91.36       605.5           0.14510            0.13790   \n",
       "..               ...         ...               ...                ...   \n",
       "164            86.54       562.6           0.12890            0.13520   \n",
       "165           125.00      1102.0           0.15310            0.35830   \n",
       "166            79.73       447.1           0.10950            0.19820   \n",
       "167           199.50      3143.0           0.13630            0.16280   \n",
       "168           122.40       896.9           0.15250            0.66430   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0            0.00000               0.00000          0.2932   \n",
       "1            0.03866               0.03333          0.2458   \n",
       "2            0.32150               0.16280          0.2572   \n",
       "3            0.42510               0.19410          0.2818   \n",
       "4            0.08539               0.07407          0.2710   \n",
       "..               ...                   ...             ...   \n",
       "164          0.04506               0.05093          0.2880   \n",
       "165          0.58300               0.18270          0.3216   \n",
       "166          0.15530               0.06754          0.3202   \n",
       "167          0.28610               0.18200          0.2510   \n",
       "168          0.55390               0.27010          0.4264   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.09382  \n",
       "1                    0.06120  \n",
       "2                    0.06637  \n",
       "3                    0.10050  \n",
       "4                    0.07191  \n",
       "..                       ...  \n",
       "164                  0.08083  \n",
       "165                  0.10100  \n",
       "166                  0.07287  \n",
       "167                  0.06494  \n",
       "168                  0.12750  \n",
       "\n",
       "[169 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2       True\n",
       "3       True\n",
       "4      False\n",
       "       ...  \n",
       "164    False\n",
       "165     True\n",
       "166    False\n",
       "167     True\n",
       "168     True\n",
       "Name: malignant, Length: 169, dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = pd.read_excel('Files/TEST_breast_cancer_kaggle.xls')\n",
    "display(df_test.head())\n",
    "x_test = df_test.iloc[:, 0:30]\n",
    "y_test = df_test['malignant']\n",
    "\n",
    "display(x_test)\n",
    "display(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Explain succinctly whether we are dealing with a regression or a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This is a classification problem because we are looking for labels.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a logistic regression model and train it using the training data (`X`, `y`). Now calculate the training accuracy and the test accuracy, that is:\n",
    "    - Use the trained model to make predictions from the training `X`;\n",
    "    - Evaluate the accuracy of your prediction, that is, the percentage of predictions that coincide exactly with `y` (training accuracy);\n",
    "    - Use the logistic regression you trained using `X` to make predictions for the test `X_test`;\n",
    "    - Evaluate the accuracy of your prediction, that is, the percentage of predictions that coincide exactly with `y_test` (test accuracy).\n",
    "    - Is the test accuracy larger or smaller than the training accuracy? Why? Which one is a good measure of the predictive power of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.96\n",
      "Test accuracy: 0.9467455621301775\n",
      "The test accuracy is lower than the training accuracy. This may indicate a slight overfitting.\n",
      "Conclusion: test accuracy is the best measure of predictive power in new data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# model de regressió logística amb les dades d'entrenament\n",
    "model = LogisticRegression(max_iter=5000) #he augmentat el número de iteracions per a que convergeixi, ja que em saltava un warning. Per fer-ho més ràpid també es podrien normalitzar les dades. \n",
    "model.fit(x, y)  # x i y definits prèviament\n",
    "\n",
    "# Prediccions del conjunt d'entrenament\n",
    "y_pred_train = model.predict(x)\n",
    "training_accuracy = accuracy_score(y, y_pred_train)\n",
    "print(\"Training accuracy:\", training_accuracy)\n",
    "\n",
    "# Prediccions del conjunt test\n",
    "y_pred_test = model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "# Pregunta final de raonament: \n",
    "if test_accuracy < training_accuracy:\n",
    "    print(\"The test accuracy is lower than the training accuracy. This may indicate a slight overfitting.\")\n",
    "else:\n",
    "    print(\"The test accuracy is equal to or greater than the training accuracy. The model seems to generalize well.\")\n",
    "\n",
    "print(\"Conclusion: test accuracy is the best measure of predictive power in new data.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Do the same as in 5, but training a RF model instead of a logistic regression model. Use the default values for the RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 94.0828402366864 % of coincidence between x_test and y_test (Test Accuracy)\n",
      "There is a 100.0 % of coincidence between x and y (Training Accuracy)\n",
      "The test accuracy is lower than the training accuracy. This may indicate overfitting.\n",
      "Conclusion: test accuracy is the best measure of predictive power in new data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()  # default: n_estimators=100\n",
    "\n",
    "clf.fit(x, y) # així entrenem el model amb les dades d'entrenament\n",
    "\n",
    "# Prediccions del conjunt de test i entrenament\n",
    "y_pred_test_rf = clf.predict(x_test)\n",
    "y_pred_train_rf = clf.predict(x)\n",
    "\n",
    "# Càlcul d’accuracy sobre el test set\n",
    "accuracy_test_rf = accuracy_score(y_test, y_pred_test_rf) * 100 #%\n",
    "\n",
    "# Càlcul d’accuracy sobre el training set\n",
    "accuracy_train_rf = accuracy_score(y, y_pred_train_rf) * 100 #%\n",
    "\n",
    "# Mostrem els resultats\n",
    "print(\"There is a\", accuracy_test_rf, \"% of coincidence between x_test and y_test (Test Accuracy)\")\n",
    "print(\"There is a\", accuracy_train_rf, \"% of coincidence between x and y (Training Accuracy)\")\n",
    "\n",
    "# Pregunta final de raonament:\n",
    "if accuracy_test_rf < accuracy_train_rf:\n",
    "    print(\"The test accuracy is lower than the training accuracy. This may indicate overfitting.\")\n",
    "else:\n",
    "    print(\"The test accuracy is equal or higher than the training accuracy. The model generalizes well.\")\n",
    "\n",
    "print(\"Conclusion: test accuracy is the best measure of predictive power in new data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Do the same as in 5, but training a SVM model instead of a logistic regression model. Use an `rbf` (radial basin funcion) kernel for the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 94.67% of coincidence between x_test and y_test (Test Accuracy)\n",
      "There is a 91.00% of coincidence between x and y (Training Accuracy)\n",
      "The test accuracy is equal or higher than the training accuracy. The model generalizes well.\n",
      "Conclusion: test accuracy is the best measure of predictive power in new data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Creem el model SVM amb kernel RBF\n",
    "svm_model = SVC(kernel='rbf')\n",
    "\n",
    "svm_model.fit(x, y) # entreno el model\n",
    "\n",
    "# Prediccions\n",
    "y_pred_train_svm = svm_model.predict(x)\n",
    "y_pred_test_svm = svm_model.predict(x_test)\n",
    "\n",
    "# càlcul precisió\n",
    "accuracy_train_svm = accuracy_score(y, y_pred_train_svm) * 100\n",
    "accuracy_test_svm = accuracy_score(y_test, y_pred_test_svm) * 100\n",
    "\n",
    "\n",
    "print(f\"There is a {accuracy_test_svm:.2f}% of coincidence between x_test and y_test (Test Accuracy)\")\n",
    "print(f\"There is a {accuracy_train_svm:.2f}% of coincidence between x and y (Training Accuracy)\")\n",
    "if accuracy_test_svm < accuracy_train_svm:\n",
    "    print(\"The test accuracy is lower than the training accuracy. This may indicate overfitting.\")\n",
    "else:\n",
    "    print(\"The test accuracy is equal or higher than the training accuracy. The model generalizes well.\")\n",
    "\n",
    "print(\"Conclusion: test accuracy is the best measure of predictive power in new data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Do the same as in 5, but training a neural network (multilayer perceptron, MLP) model instead of a logistic regression model. Create a network with two hidden layers of sizes 100 and 100 (that is, with 100 units each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 95.27% of coincidence between x_test and y_test (Test Accuracy)\n",
      "There is a 92.00% of coincidence between x and y (Training Accuracy)\n",
      "The test accuracy is equal or higher than the training accuracy. The model generalizes well.\n",
      "Conclusion: test accuracy is the best measure of predictive power in new data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, random_state=42) # dues capes amagades de 100 neurones cadascuna\n",
    "\n",
    "mlp_model.fit(x, y) # Entrenem el model\n",
    "\n",
    "# Prediccions\n",
    "y_pred_train_mlp = mlp_model.predict(x)\n",
    "y_pred_test_mlp = mlp_model.predict(x_test)\n",
    "\n",
    "# càlcul precisió\n",
    "accuracy_train_mlp = accuracy_score(y, y_pred_train_mlp) * 100\n",
    "accuracy_test_mlp = accuracy_score(y_test, y_pred_test_mlp) * 100\n",
    "\n",
    "print(f\"There is a {accuracy_test_mlp:.2f}% of coincidence between x_test and y_test (Test Accuracy)\")\n",
    "print(f\"There is a {accuracy_train_mlp:.2f}% of coincidence between x and y (Training Accuracy)\")\n",
    "if accuracy_test_mlp < accuracy_train_mlp:\n",
    "    print(\"The test accuracy is lower than the training accuracy. This may indicate overfitting.\")\n",
    "else:\n",
    "    print(\"The test accuracy is equal or higher than the training accuracy. The model generalizes well.\")\n",
    "\n",
    "print(\"Conclusion: test accuracy is the best measure of predictive power in new data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now, with the SVM model, do the following:\n",
    "\n",
    "9. Use 5-fold cross-validation in the training set (that is, ignoring for now the test set) to calculate validation accuracy. Is the validation accuracy a good estimate of the test accuracy? That is, is the validation accuracy similar to the test accuracy that you calculated earlier in question 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracies per fold: [0.9   0.925 0.875 0.9   0.9  ]\n",
      "Mean validation accuracy: 90.00%\n",
      "Standard deviation: 1.58%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(svm_model, x, y, cv=5, scoring='accuracy') # 5-fold cross-validation sobre el conjunt d'entrenament\n",
    "\n",
    "print(\"Cross-validation accuracies per fold:\", cv_scores)\n",
    "print(f\"Mean validation accuracy: {cv_scores.mean() * 100:.2f}%\")\n",
    "print(f\"Standard deviation: {cv_scores.std() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Use 5-fold cross-validation to optimize the parameters of your SVM model (in other words, use the value of the validation accuracy to select the optimal values of the parameters). Then, calculate the *test* accuracy using the optimized model. Did it improve with respect to the original test accuracy? (**Note:** By model parameters we mean, for [the SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), parameters like the \"budget\" or regularization parameter C, the kernel function, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 0.95 f1_macro score with a linear kernel and C=1 (std: 0.02)\n",
      "There is a 0.95 f1_macro score with a linear kernel and C=2 (std: 0.02)\n",
      "There is a 0.89 f1_macro score with a poly kernel and C=1 (std: 0.02)\n",
      "There is a 0.89 f1_macro score with a poly kernel and C=2 (std: 0.01)\n",
      "There is a 0.89 f1_macro score with an RBF kernel and C=1 (std: 0.02)\n",
      "Using cross-validation error improves, as the test error has diminished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# SVM amb kernel lineal i C=1\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, x, y, cv=5, scoring='f1_macro')\n",
    "print(\"There is a %0.2f f1_macro score with a linear kernel and C=1 (std: %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# SVM amb kernel lineal i C=2\n",
    "clf = svm.SVC(kernel='linear', C=2, random_state=42)\n",
    "scores = cross_val_score(clf, x, y, cv=5, scoring='f1_macro')\n",
    "print(\"There is a %0.2f f1_macro score with a linear kernel and C=2 (std: %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# SVM amb kernel polinòmic i C=1\n",
    "clf = svm.SVC(kernel='poly', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, x, y, cv=5, scoring='f1_macro')\n",
    "print(\"There is a %0.2f f1_macro score with a poly kernel and C=1 (std: %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# SVM amb kernel polinòmic i C=2\n",
    "clf = svm.SVC(kernel='poly', C=2, random_state=42)\n",
    "scores = cross_val_score(clf, x, y, cv=5, scoring='f1_macro')\n",
    "print(\"There is a %0.2f f1_macro score with a poly kernel and C=2 (std: %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# SVM amb kernel RBF i C=1\n",
    "clf = svm.SVC(kernel='rbf', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, x, y, cv=5, scoring='f1_macro')\n",
    "print(\"There is a %0.2f f1_macro score with an RBF kernel and C=1 (std: %0.2f)\" % (scores.mean(), scores.std()))\n",
    "\n",
    "print(\"Using cross-validation error improves, as the test error has diminished\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
